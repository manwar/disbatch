#!/usr/bin/env perl

# USAGE: ./bin/task_runner --host localhost --db disbatch300 --plugin Disbatch::Plugin::Dummy::Task --task 565bc0d43fb6ecd1c8504492

# FIXME: Use the queue _id in the task to get the plugin name. Gotcha: WorkerThread has mongo setup, but wants the plugin name.
#        $workerthread->mongo->get_collection('queues')->find_one({_id => $doc->{queue}})->{constructor}
# FIXME: Do we need to even pass the queue _id at all? The task _id is unique, and the task contains the queue _id.

use 5.12.0;
use warnings;

use lib 'lib';	# FIXME: this is only needed for dev

use Cpanel::JSON::XS;
use Data::Dumper;
use Disbatch;
use Getopt::Long;
use MongoDB::OID 1.0.0;
use Try::Tiny::Retry;
use Safe::Isa;

my ($host, $db, $queue, $task_id, $plugin, $log4perl, $gfs, $config_file);

GetOptions(
    'host=s'     => \$host,
    'db=s'       => \$db,
    'queue=s'    => \$queue,
    'task=s'     => \$task_id,
    'plugin=s'   => \$plugin,
    'log4perl=s' => \$log4perl,
    'gfs!'       => \$gfs,
    'config=s'   => \$config_file,
);

$gfs //= 1;	# use GridFS by default

my $json = Cpanel::JSON::XS->new->utf8;

my $disbatch;
if (defined $config_file) {
    $disbatch = Disbatch->new(class => $plugin, config_file => $config_file);
    $disbatch->load_config;
} else {
    my $config = { mongohost => $host, database => $db };
    $config->{log4perl} = try { $json->decode($log4perl) } if defined $log4perl;
    $config->{log4perl} //= {
        level => 'TRACE',
        appenders => {
            screenlog => { type => 'Log::Log4perl::Appender::ScreenColoredLevels' },
            filelog => { type => 'Log::Log4perl::Appender::File', args => { filename => '/tmp/' . ($task_id // 'task_runner') } },
        },
    };
    $disbatch = Disbatch->new(class => $plugin, config => $config);
}

my $logger = $disbatch->logger;

$logger->info("Starting task $task_id");

unless (defined $config_file or (defined $host and defined $db)) {
    $logger->logdie('Either --config or --host and --db options must be used');
}
if (defined $config_file and (defined $host and defined $db)) {
    $logger->logdie('--host and --db options cannot be used with --config');
}

$logger->logdie('No --task') unless defined $task_id;
$logger->logdie('No --plugin') unless defined $plugin;
#$logger->logdie('No --queue') unless defined $queue;
$logger->logdie("--plugin value '$plugin' must be a valid perl package name, matching /^[\\w:]+\$/") unless $plugin =~ /^[\w:]+$/;
$logger->logdie("$plugin not found for task $task_id") unless eval "use $plugin; 1";

my $oid = try { MongoDB::OID->new(value => $task_id) } catch { $logger->logdie($_) };
my $doc = retry {
    $disbatch->tasks->find_one_and_update({_id => $oid, status => -1, node => $disbatch->{node}}, {'$set' => {status => 0}});
} catch {
    $logger->logdie("Could not find and set task $task_id to status 0: $_");
};

$logger->logdie("No task found for $task_id") unless defined $doc;
$logger->info("parameters for $task_id: ", $json->encode($doc->{parameters}));

my $task = try {
    $plugin->new({id => $queue}, $doc->{parameters});
} catch {
    $logger->logdie($_);
};
$task->{workerthread} = $disbatch;
$task->{id} = $oid;

my ($query, $result) = try {
    $task->run;
} catch {
    $logger->error("Thread has uncaught exception: $_");
    {queue => $queue, _id => $task_id}, {status => 2, stdout => 'Unable to complete', stderr => "Thread has uncaught exception: $_"};
};
my $status = $result->{status} == 1 ? 'succeeded' : 'failed';
$logger->info("Task $task_id $status.");
warn "STDOUT: $result->{stdout}";
warn "STDERR: $result->{stderr}";

# set status first:
retry { $disbatch->tasks->update_one({_id => $oid, status => 0, node => $disbatch->{node}}, {'$set' => {status => $result->{status}}}) }
catch { $logger->logdie("Could not update task $task_id status to $result->{status} after completion: $_") };

# decrement count_todo
try { $disbatch->queues->update_one({_id => $doc->{queue}}, {'$inc' => {count_todo => -1}}) } catch { $logger->error("Could not decrement count_todo for queue $doc->{queue}: $_") };

# set rest of result:
if ($gfs) {
    my $stdout_doc = retry { $disbatch->put_gfs($result->{stdout}, 'stdout', { task_id => $oid }) } catch { $logger->error("Could not create GridFS content for task $oid stdout: $_"); {} };
    my $stderr_doc = retry { $disbatch->put_gfs($result->{stderr}, 'stderr', { task_id => $oid }) } catch { $logger->error("Could not create GridFS content for task $oid stderr: $_"); {} };
    $result->{stdout} = $stdout_doc->{_id};
    $result->{stderr} = $stderr_doc->{_id};
    retry { $disbatch->tasks->update_one({_id => $oid, status => $result->{status}, node => $disbatch->{node}}, {'$set' => $result}) }
    catch { $logger->logdie("Could not update task $task_id stdout/stderr file ids after completion: $_") };
} else {
    retry { $disbatch->tasks->update_one({_id => $oid, status => $result->{status}, node => $disbatch->{node}}, {'$set' => $result}) }
    on_retry { $result->{stdout} = $_ if $_->$_isa('MongoDB::DocumentError') }	# MongoDB::DocumentError: Document exceeds maximum size 16777216
    catch { $logger->logdie("Could not update task $task_id stdout/stderr after completion: $_") };
}
